{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bassendiaye/lowdiscovery/blob/main/1_Pre_traitement_spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7511e8",
      "metadata": {
        "id": "0e7511e8"
      },
      "source": [
        "# TP: Pré-traitement avec spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "825d6e07-8436-4dea-8c61-cc0ae52f4180",
      "metadata": {
        "id": "825d6e07-8436-4dea-8c61-cc0ae52f4180"
      },
      "source": [
        "Pour des problèmes de compatibilité de bibliothèques python, il se pourrait que vous soyez obligés d'installer des versions antérieures pour certains modules (numpy, scipy, pandas, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a085c20c-9715-4e69-b95a-6b1680476dfc",
      "metadata": {
        "id": "a085c20c-9715-4e69-b95a-6b1680476dfc",
        "outputId": "032c00ca-69c5-4b15-a4d0-2b5c328df248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: scipy 1.10.1\n",
            "Uninstalling scipy-1.10.1:\n",
            "  Successfully uninstalled scipy-1.10.1\n",
            "Found existing installation: matplotlib 3.8.0\n",
            "Uninstalling matplotlib-3.8.0:\n",
            "  Successfully uninstalled matplotlib-3.8.0\n",
            "Found existing installation: contourpy 1.2.0\n",
            "Uninstalling contourpy-1.2.0:\n",
            "  Successfully uninstalled contourpy-1.2.0\n",
            "Found existing installation: pandas 1.5.3\n",
            "Uninstalling pandas-1.5.3:\n",
            "  Successfully uninstalled pandas-1.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip3 uninstall numpy scipy matplotlib contourpy pandas --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a6e6a6-f09d-4db5-a6a6-59467d67044c",
      "metadata": {
        "id": "89a6e6a6-f09d-4db5-a6a6-59467d67044c",
        "outputId": "6d975285-679f-46a0-904d-ecdf64640d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.22.4\n",
            "  Using cached numpy-1.22.4.zip (11.5 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting scipy==1.9\n",
            "  Downloading scipy-1.9.0.tar.gz (42.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[67 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m The Meson build system\n",
            "  \u001b[31m   \u001b[0m Version: 0.62.2\n",
            "  \u001b[31m   \u001b[0m Source dir: /private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6\n",
            "  \u001b[31m   \u001b[0m Build dir: /private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6/.mesonpy-zh6r2mv0/build\n",
            "  \u001b[31m   \u001b[0m Build type: native build\n",
            "  \u001b[31m   \u001b[0m Project name: SciPy\n",
            "  \u001b[31m   \u001b[0m Project version: 1.9.0\n",
            "  \u001b[31m   \u001b[0m C compiler for the host machine: cc (clang 15.0.0 \"Apple clang version 15.0.0 (clang-1500.3.9.4)\")\n",
            "  \u001b[31m   \u001b[0m C linker for the host machine: cc ld64 1053.12\n",
            "  \u001b[31m   \u001b[0m C++ compiler for the host machine: c++ (clang 15.0.0 \"Apple clang version 15.0.0 (clang-1500.3.9.4)\")\n",
            "  \u001b[31m   \u001b[0m C++ linker for the host machine: c++ ld64 1053.12\n",
            "  \u001b[31m   \u001b[0m Host machine cpu family: x86_64\n",
            "  \u001b[31m   \u001b[0m Host machine cpu: x86_64\n",
            "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
            "  \u001b[31m   \u001b[0m Library m found: YES\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m ../../meson.build:41:0: ERROR: Unknown compiler(s): [['gfortran'], ['flang'], ['nvfortran'], ['pgfortran'], ['ifort'], ['g95']]\n",
            "  \u001b[31m   \u001b[0m The following exception(s) were encountered:\n",
            "  \u001b[31m   \u001b[0m Running \"gfortran --version\" gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
            "  \u001b[31m   \u001b[0m Running \"gfortran -V\" gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
            "  \u001b[31m   \u001b[0m Running \"flang --version\" gave \"[Errno 2] No such file or directory: 'flang'\"\n",
            "  \u001b[31m   \u001b[0m Running \"flang -V\" gave \"[Errno 2] No such file or directory: 'flang'\"\n",
            "  \u001b[31m   \u001b[0m Running \"nvfortran --version\" gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
            "  \u001b[31m   \u001b[0m Running \"nvfortran -V\" gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
            "  \u001b[31m   \u001b[0m Running \"pgfortran --version\" gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
            "  \u001b[31m   \u001b[0m Running \"pgfortran -V\" gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
            "  \u001b[31m   \u001b[0m Running \"ifort --version\" gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
            "  \u001b[31m   \u001b[0m Running \"ifort -V\" gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
            "  \u001b[31m   \u001b[0m Running \"g95 --version\" gave \"[Errno 2] No such file or directory: 'g95'\"\n",
            "  \u001b[31m   \u001b[0m Running \"g95 -V\" gave \"[Errno 2] No such file or directory: 'g95'\"\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m A full log can be found at /private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6/.mesonpy-zh6r2mv0/build/meson-logs/meson-log.txt\n",
            "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ meson setup --native-file=/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6/.mesonpy-native-file.ini -Ddebug=false -Doptimization=2 --prefix=/opt/anaconda3 /private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6 /private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6/.mesonpy-zh6r2mv0/build\u001b[0m\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
            "  \u001b[31m   \u001b[0m     main()\n",
            "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
            "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
            "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
            "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-build-env-f9se8pc0/overlay/lib/python3.11/site-packages/mesonpy/__init__.py\", line 909, in get_requires_for_build_wheel\n",
            "  \u001b[31m   \u001b[0m     with _project(config_settings) as project:\n",
            "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.11/contextlib.py\", line 137, in __enter__\n",
            "  \u001b[31m   \u001b[0m     return next(self.gen)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-build-env-f9se8pc0/overlay/lib/python3.11/site-packages/mesonpy/__init__.py\", line 888, in _project\n",
            "  \u001b[31m   \u001b[0m     with Project.with_temp_working_dir(\n",
            "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.11/contextlib.py\", line 137, in __enter__\n",
            "  \u001b[31m   \u001b[0m     return next(self.gen)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-build-env-f9se8pc0/overlay/lib/python3.11/site-packages/mesonpy/__init__.py\", line 547, in with_temp_working_dir\n",
            "  \u001b[31m   \u001b[0m     yield cls(source_dir, tmpdir, build_dir)\n",
            "  \u001b[31m   \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-build-env-f9se8pc0/overlay/lib/python3.11/site-packages/mesonpy/__init__.py\", line 463, in __init__\n",
            "  \u001b[31m   \u001b[0m     self._configure(reconfigure=bool(build_dir) and not native_file_mismatch)\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-build-env-f9se8pc0/overlay/lib/python3.11/site-packages/mesonpy/__init__.py\", line 494, in _configure\n",
            "  \u001b[31m   \u001b[0m     self._meson(\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-build-env-f9se8pc0/overlay/lib/python3.11/site-packages/mesonpy/__init__.py\", line 477, in _meson\n",
            "  \u001b[31m   \u001b[0m     return self._proc('meson', *args)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-build-env-f9se8pc0/overlay/lib/python3.11/site-packages/mesonpy/__init__.py\", line 472, in _proc\n",
            "  \u001b[31m   \u001b[0m     subprocess.check_call(list(args))\n",
            "  \u001b[31m   \u001b[0m   File \"/opt/anaconda3/lib/python3.11/subprocess.py\", line 413, in check_call\n",
            "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
            "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['meson', 'setup', '--native-file=/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6/.mesonpy-native-file.ini', '-Ddebug=false', '-Doptimization=2', '--prefix=/opt/anaconda3', '/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6', '/private/var/folders/g4/2_1sz3ps3bz11wxp2cbhd7c00000gn/T/pip-install-0vobx13h/scipy_82f126d061c8467d94b1a07ea090def6/.mesonpy-zh6r2mv0/build']' returned non-zero exit status 1.\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install numpy==1.22.4 scipy==1.9 matplotlib==3.8.0 contourpy==1.2.0 pandas==2.2.0 pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9759f16e-c4bb-45de-9aec-997f3808ccde",
      "metadata": {
        "id": "9759f16e-c4bb-45de-9aec-997f3808ccde"
      },
      "source": [
        "## Installer et importer spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1fe83fc",
      "metadata": {
        "id": "a1fe83fc"
      },
      "source": [
        "Pour l'installation, visitez le site: https://spacy.io/usage.\n",
        "Vous entrez les paramètres de votre appareil (Mac, Windows,Linux) et votre langue (par exemple français) et l'application Web affichera automatiquement les commandes que vous devez exécuter pour commencer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44efef19",
      "metadata": {
        "id": "44efef19"
      },
      "source": [
        "Pour l'installation sur JupyterBook, nous allons utiliser \"!\" pour exécuter une commande de terminal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "875aa673-4186-4e38-84cd-34db5f6de5c2",
      "metadata": {
        "id": "875aa673-4186-4e38-84cd-34db5f6de5c2",
        "outputId": "96ddca3b-3eb5-4ea8-9809-c005db8a3841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /opt/anaconda3/lib/python3.11/site-packages (3.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (8.3.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (68.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from spacy) (3.4.1)\n",
            "Collecting numpy>=1.19.0 (from spacy)\n",
            "  Using cached numpy-2.1.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: language-data>=1.2 in /opt/anaconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<1.1.0,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
            "  Using cached numpy-2.0.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/anaconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
            "Using cached numpy-2.0.2-cp311-cp311-macosx_10_9_x86_64.whl (21.2 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "streamlit 1.30.0 requires pandas<3,>=1.3.0, which is not installed.\n",
            "statsmodels 0.14.0 requires pandas>=1.0, which is not installed.\n",
            "statsmodels 0.14.0 requires scipy!=1.9.2,>=1.4, which is not installed.\n",
            "bokeh 3.3.4 requires contourpy>=1, which is not installed.\n",
            "bokeh 3.3.4 requires pandas>=1.2, which is not installed.\n",
            "scikit-learn 1.2.2 requires scipy>=1.3.2, which is not installed.\n",
            "panel 1.3.8 requires pandas>=1.2, which is not installed.\n",
            "fuzzytm 2.0.9 requires pandas, which is not installed.\n",
            "fuzzytm 2.0.9 requires scipy, which is not installed.\n",
            "imbalanced-learn 0.11.0 requires scipy>=1.5.0, which is not installed.\n",
            "scikit-image 0.22.0 requires scipy>=1.8, which is not installed.\n",
            "hvplot 0.9.2 requires pandas, which is not installed.\n",
            "altair 5.0.1 requires pandas>=0.18, which is not installed.\n",
            "miniful 0.0.6 requires scipy>=1.0.0, which is not installed.\n",
            "holoviews 1.18.3 requires pandas>=0.20.0, which is not installed.\n",
            "pyfume 0.3.4 requires pandas==1.5.3, which is not installed.\n",
            "pyfume 0.3.4 requires scipy==1.10.1, which is not installed.\n",
            "simpful 2.12.0 requires scipy>=1.0.0, which is not installed.\n",
            "gensim 4.3.0 requires scipy>=1.7.0, which is not installed.\n",
            "seaborn 0.12.2 requires matplotlib!=3.6.1,>=3.1, which is not installed.\n",
            "seaborn 0.12.2 requires pandas>=0.25, which is not installed.\n",
            "datashader 0.16.0 requires pandas, which is not installed.\n",
            "datashader 0.16.0 requires scipy, which is not installed.\n",
            "xarray 2023.6.0 requires pandas>=1.4, which is not installed.\n",
            "streamlit 1.30.0 requires numpy<2,>=1.19.3, but you have numpy 2.0.2 which is incompatible.\n",
            "tensorflow 2.16.2 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\n",
            "astropy 5.3.4 requires numpy<2,>=1.21, but you have numpy 2.0.2 which is incompatible.\n",
            "numba 0.59.0 requires numpy<1.27,>=1.22, but you have numpy 2.0.2 which is incompatible.\n",
            "pyfume 0.3.4 requires numpy==1.24.4, but you have numpy 2.0.2 which is incompatible.\n",
            "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -U spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e35f8ee2",
      "metadata": {
        "id": "e35f8ee2"
      },
      "source": [
        "Ensuite, nous télechargeons les modèles pour le français (par exemple fr_core_news_sm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35d6c747",
      "metadata": {
        "id": "35d6c747"
      },
      "source": [
        "Nous importons spacy pour nous assurer que nous l'avons installé correctement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9768615",
      "metadata": {
        "id": "d9768615"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2176ac",
      "metadata": {
        "id": "3d2176ac"
      },
      "source": [
        "Spacy fournit le concept de conteneur **Doc**, c'est-à-dire des objets qui contiennent une grande quantité de données sur un texte. Il existe différents types de conteneur:\n",
        "* Doc\n",
        "* Token\n",
        "* ...\n",
        "\n",
        "Le conteneur **Doc** comporte de nombreux attributs et sous-conteneurs, entre autres\n",
        "\n",
        "* **Doc.sents**: contient toutes les phrases du conteneur Doc.\n",
        "* **Token**: un conteneur qui contient les tokens (mots, signes de ponctuation, etc.)\n",
        "\n",
        "Les Token ne sont pas des strings, mais des objets qui viennent avec plusieurs attributs, entre autres:\n",
        "\n",
        "* .text: forme d'un token\n",
        "* .lemma_: le lemme d'un token\n",
        "* .pos_: la catégorie grammaticale d'un token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7ff049d",
      "metadata": {
        "id": "f7ff049d"
      },
      "source": [
        "## Pré-traitement de corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5ce9df1",
      "metadata": {
        "id": "f5ce9df1"
      },
      "source": [
        "Pour ce démo, nous allons utiliser notre petit corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca45a52",
      "metadata": {
        "id": "dca45a52"
      },
      "outputs": [],
      "source": [
        "corpus = \"\"\"Le cinéma est un art, c’est aussi une industrie. Personne quand il est petit, ne veut être critique de cinéma. Mais ensuite, en France, tout le monde a un deuxième métier : critique de cinéma ! Tout le monde a des rêves de Hollywood. C'est la crise, l'économie de la France est menacée par la mondialisation. En temps de crise, reconstruire l'industrie : tout un art! Quand une usine ferme, c'est que l'économie va mal.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e43f84-9688-453f-9c60-e71c02d12df9",
      "metadata": {
        "id": "d9e43f84-9688-453f-9c60-e71c02d12df9"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('fr_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa055e17",
      "metadata": {
        "id": "aa055e17"
      },
      "outputs": [],
      "source": [
        "doc = nlp(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23b75c4a-214c-4f56-953c-a7ac96d56fe2",
      "metadata": {
        "id": "23b75c4a-214c-4f56-953c-a7ac96d56fe2",
        "outputId": "f8d61d08-de05-4862-c9c5-bbedf5026124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "# doc.sent contient les phrases du conteneur doc. Nous pouvons ainsi demander le nbre de phrases du conteneur\n",
        "print(len(list(doc.sents)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "741e0b78",
      "metadata": {
        "id": "741e0b78"
      },
      "source": [
        "### Découpage en phrases (sentence tokenisation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b63536d",
      "metadata": {
        "id": "0b63536d",
        "outputId": "e2f412e3-2bb2-4d0e-e76a-d00cf31e96e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le cinéma est un art, c’est aussi une industrie.\n",
            "Personne quand il est petit, ne veut être critique de cinéma.\n",
            "Mais ensuite, en France, tout le monde a un deuxième métier : critique de cinéma !\n",
            "Tout le monde a des rêves de Hollywood.\n",
            "C'est la crise, l'économie de la France est menacée par la mondialisation.\n",
            "En temps de crise, reconstruire l'industrie : tout un art!\n",
            "Quand une usine ferme, c'est que l'économie va mal.\n"
          ]
        }
      ],
      "source": [
        "for phrase in doc.sents:\n",
        "    print(phrase)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8abd59dd",
      "metadata": {
        "id": "8abd59dd"
      },
      "source": [
        "Découper les phrases sous forme de liste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd951022",
      "metadata": {
        "id": "bd951022",
        "outputId": "87055963-6cd3-4081-a63e-964603c08ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Le cinéma est un art, c’est aussi une industrie.', 'Personne quand il est petit, ne veut être critique de cinéma.', 'Mais ensuite, en France, tout le monde a un deuxième métier : critique de cinéma !', 'Tout le monde a des rêves de Hollywood.', \"C'est la crise, l'économie de la France est menacée par la mondialisation.\", \"En temps de crise, reconstruire l'industrie : tout un art!\", \"Quand une usine ferme, c'est que l'économie va mal.\"]\n"
          ]
        }
      ],
      "source": [
        "# créer une liste de phrases\n",
        "list_de_phrases = []\n",
        "for phrase in doc.sents:\n",
        "    list_de_phrases.append(phrase.text)\n",
        "print(list_de_phrases)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "779d5053",
      "metadata": {
        "id": "779d5053"
      },
      "source": [
        "### Découpage en mots (tokenisation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4771e6",
      "metadata": {
        "id": "bf4771e6",
        "outputId": "119823c3-ac2b-414b-a0a0-9239b8819042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le\n",
            "cinéma\n",
            "est\n",
            "un\n",
            "art\n",
            ",\n",
            "c’\n",
            "est\n",
            "aussi\n",
            "une\n",
            "industrie\n",
            ".\n",
            "Personne\n",
            "quand\n",
            "il\n",
            "est\n",
            "petit\n",
            ",\n",
            "ne\n",
            "veut\n",
            "être\n",
            "critique\n",
            "de\n",
            "cinéma\n",
            ".\n",
            "Mais\n",
            "ensuite\n",
            ",\n",
            "en\n",
            "France\n",
            ",\n",
            "tout\n",
            "le\n",
            "monde\n",
            "a\n",
            "un\n",
            "deuxième\n",
            "métier\n",
            ":\n",
            "critique\n",
            "de\n",
            "cinéma\n",
            "!\n",
            "Tout\n",
            "le\n",
            "monde\n",
            "a\n",
            "des\n",
            "rêves\n",
            "de\n",
            "Hollywood\n",
            ".\n",
            "C'\n",
            "est\n",
            "la\n",
            "crise\n",
            ",\n",
            "l'\n",
            "économie\n",
            "de\n",
            "la\n",
            "France\n",
            "est\n",
            "menacée\n",
            "par\n",
            "la\n",
            "mondialisation\n",
            ".\n",
            "En\n",
            "temps\n",
            "de\n",
            "crise\n",
            ",\n",
            "reconstruire\n",
            "l'\n",
            "industrie\n",
            ":\n",
            "tout\n",
            "un\n",
            "art\n",
            "!\n",
            "Quand\n",
            "une\n",
            "usine\n",
            "ferme\n",
            ",\n",
            "c'\n",
            "est\n",
            "que\n",
            "l'\n",
            "économie\n",
            "va\n",
            "mal\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(token.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87ef747",
      "metadata": {
        "id": "e87ef747",
        "outputId": "bd41a5d5-c1bc-4514-b116-76c8e5a26671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Le', 'cinéma', 'est', 'un', 'art', ',', 'c’', 'est', 'aussi', 'une', 'industrie', '.', 'Personne', 'quand', 'il', 'est', 'petit', ',', 'ne', 'veut', 'être', 'critique', 'de', 'cinéma', '.', 'Mais', 'ensuite', ',', 'en', 'France', ',', 'tout', 'le', 'monde', 'a', 'un', 'deuxième', 'métier', ':', 'critique', 'de', 'cinéma', '!', 'Tout', 'le', 'monde', 'a', 'des', 'rêves', 'de', 'Hollywood', '.', \"C'\", 'est', 'la', 'crise', ',', \"l'\", 'économie', 'de', 'la', 'France', 'est', 'menacée', 'par', 'la', 'mondialisation', '.', 'En', 'temps', 'de', 'crise', ',', 'reconstruire', \"l'\", 'industrie', ':', 'tout', 'un', 'art', '!', 'Quand', 'une', 'usine', 'ferme', ',', \"c'\", 'est', 'que', \"l'\", 'économie', 'va', 'mal', '.']\n"
          ]
        }
      ],
      "source": [
        "# Construire une liste de tokens (mots)\n",
        "token_list = []\n",
        "for token in doc:\n",
        "    token_list.append(token.text)\n",
        "print(token_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fa1e7e2",
      "metadata": {
        "id": "1fa1e7e2"
      },
      "source": [
        "## Normalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4efdd0f8",
      "metadata": {
        "id": "4efdd0f8"
      },
      "source": [
        "### Suppression des mots vides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e5f040",
      "metadata": {
        "id": "38e5f040"
      },
      "outputs": [],
      "source": [
        "french_stopwords = spacy.lang.fr.stop_words.STOP_WORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52da4a0",
      "metadata": {
        "id": "a52da4a0",
        "outputId": "550347c8-558c-4c15-ce6a-c0f7e6960a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de mots vides (stop words): 507\n"
          ]
        }
      ],
      "source": [
        "#Afficher le nombre total de mots vides\n",
        "print('Nombre de mots vides (stop words): %d' % len(french_stopwords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95b54a7",
      "metadata": {
        "id": "d95b54a7",
        "outputId": "27bc63e9-eee8-4db1-c0bb-029bb98c67e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['vingt',\n",
              " 'avec',\n",
              " 'moi-même',\n",
              " 'sont',\n",
              " 'déjà',\n",
              " 'chacune',\n",
              " 'laquelle',\n",
              " 'hormis',\n",
              " 'dix-huit',\n",
              " 'pres',\n",
              " 'celles',\n",
              " 'alors',\n",
              " 'd’',\n",
              " 'dont',\n",
              " 'devra',\n",
              " 'nos',\n",
              " 'suivantes',\n",
              " 'plusieurs',\n",
              " 'surtout',\n",
              " 'peu']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Afficher quelques mots vides\n",
        "list(french_stopwords)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4def4d3f",
      "metadata": {
        "id": "4def4d3f"
      },
      "source": [
        "La liste des mots vides peut nécissiter certaines modifications (suppression de certains mots de laliste, ajout de nouveaux mots, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510fe0ec",
      "metadata": {
        "id": "510fe0ec"
      },
      "outputs": [],
      "source": [
        "# Ajouter quelques mots vides\n",
        "french_stopwords.add('mal')\n",
        "french_stopwords.add('ensuite')\n",
        "french_stopwords.add('veut')\n",
        "french_stopwords.add('jamais')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1b30cf",
      "metadata": {
        "id": "1f1b30cf"
      },
      "source": [
        "#### Éliminer les mots vides de notre corpus\n",
        "Pour cela, nous pouvons écrire d'abord une fonction nous permettant de détecter si un mot quelconque est vide ou non. Ensuite, nous utilisons cette fonction pour faire le filtrage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bca49980",
      "metadata": {
        "id": "bca49980"
      },
      "outputs": [],
      "source": [
        "# Fonction pour détecter les mots vides\n",
        "def is_stop_word(word, stop_list):\n",
        "    return str(word).lower() in stop_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc33790c",
      "metadata": {
        "id": "fc33790c"
      },
      "source": [
        "Le code suivant utilise notre fonction pour supprimer les mots vides de notre corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd719b6",
      "metadata": {
        "id": "7fd719b6",
        "outputId": "1903f10e-e9d1-4ab5-8518-9e5817a3541b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Liste des phrases sans mots vides: [cinéma, art, industrie, petit, critique, cinéma, France, monde, métier, critique, cinéma, monde, rêves, Hollywood, crise, économie, France, menacée, mondialisation, temps, crise, reconstruire, industrie, art, usine, ferme, économie]\n"
          ]
        }
      ],
      "source": [
        "#Liste des phrases sans mots vides\n",
        "filtered_sent=[]\n",
        "\n",
        "doc = nlp(corpus)\n",
        "\n",
        "# filtrer les mots vides et les signes de ponctuation\n",
        "for word in doc:\n",
        "    if not is_stop_word(word,french_stopwords) and word.is_punct==False:\n",
        "        filtered_sent.append(word)\n",
        "print(\"Liste des phrases sans mots vides:\",filtered_sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70085b68",
      "metadata": {
        "id": "70085b68"
      },
      "source": [
        "### Stemmatisation\n",
        "En principe spacy ne fournit pas directement une fonction pour raciniser des textes. Pour cela, nous allons utiliser d'autres outils NLP comme NLTK qui propose cette fonctionnalité en implémentant l'algorithme Snowball."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69c6113f",
      "metadata": {
        "id": "69c6113f"
      },
      "source": [
        "#### L'algorithme Snowball\n",
        "\n",
        "**Classe SnowballStemmer**\n",
        "\n",
        "* NLTK propose une classe de stemmer appelée SnowballStemmer\n",
        "* Elle permet d'implémenter les algorithmes de stemmatisation à utiliser dans la recherche d'informations.\n",
        "* Il supporte 15 langues non anglaises.\n",
        "* Utilisation:\n",
        "   * nous devons créer une instance avec le nom du langage que nous utilisons\n",
        "   * Puis, nous devons appeler la méthode stem()."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "682724a7",
      "metadata": {
        "id": "682724a7"
      },
      "source": [
        "##### Exemple\n",
        "\n",
        "On importe nltk, puis la classe SnowballStemmer pour implémenter l'algorithme Snowball Stemmer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10aa1f4e",
      "metadata": {
        "id": "10aa1f4e"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4376fa1a",
      "metadata": {
        "id": "4376fa1a"
      },
      "source": [
        "Nous jetons un coup d'oeil sur les langues que cet algorithme supporte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6affd37c",
      "metadata": {
        "id": "6affd37c",
        "outputId": "b451530c-d8c5-47a4-ab78-efac17d9d75e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SnowballStemmer.languages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60bee16",
      "metadata": {
        "id": "a60bee16"
      },
      "source": [
        "* Ensuite, on crée une instance de la classe SnowballStemmer avec la langue que l'on souhaite analyser.\n",
        "* Ici, nous créons un stemmer de la langue «française»."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50018d78",
      "metadata": {
        "id": "50018d78"
      },
      "outputs": [],
      "source": [
        "French_stemmer = SnowballStemmer('french')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e58f123f",
      "metadata": {
        "id": "e58f123f"
      },
      "source": [
        "Maintenant, on peut appeler la méthode **stem()** et entrer le mot que vous souhaitons stemmatiser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "128de10d",
      "metadata": {
        "id": "128de10d",
        "outputId": "7f31ba65-7ed3-4e8b-fddf-c494e3a6e457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mang\n",
            "voudr\n",
            "animal\n",
            "yeux\n",
            "dor\n",
            "couvr\n"
          ]
        }
      ],
      "source": [
        "print(French_stemmer.stem('manger'))   # sortie: mang\n",
        "\n",
        "print(French_stemmer.stem('voudrais')) # sortie: voudr\n",
        "\n",
        "print(French_stemmer.stem('animaux'))  # sortie: animal\n",
        "\n",
        "print(French_stemmer.stem('yeux'))     # sortie: yeux\n",
        "\n",
        "print(French_stemmer.stem('dors'))     # sortie: dor\n",
        "\n",
        "print(French_stemmer.stem('couvre'))   # sortie: couvr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "720f3ff7",
      "metadata": {
        "id": "720f3ff7"
      },
      "source": [
        "Nous pouvons utiliser la même technique pour raciniser notre corpus de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a084b7",
      "metadata": {
        "id": "36a084b7",
        "outputId": "01fbbd17-4ebf-4eaa-aee3-2ef125c88d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cinem\n",
            "art\n",
            "industr\n",
            "pet\n",
            "critiqu\n",
            "cinem\n",
            "franc\n",
            "mond\n",
            "méti\n",
            "critiqu\n",
            "cinem\n",
            "mond\n",
            "rêv\n",
            "hollywood\n",
            "cris\n",
            "économ\n",
            "franc\n",
            "menac\n",
            "mondialis\n",
            "temp\n",
            "cris\n",
            "reconstruir\n",
            "industr\n",
            "art\n",
            "usin\n",
            "ferm\n",
            "économ\n"
          ]
        }
      ],
      "source": [
        "for token in filtered_sent:\n",
        "    print(French_stemmer.stem(str(token)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2659301",
      "metadata": {
        "id": "b2659301"
      },
      "source": [
        "### Lemmatisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a3cf2d",
      "metadata": {
        "id": "e1a3cf2d",
        "outputId": "ac206afe-6cd9-4704-c207-9768c518042b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cinéma  ->  cinéma\n",
            "art  ->  art\n",
            "industrie  ->  industrie\n",
            "petit  ->  petit\n",
            "critique  ->  critique\n",
            "cinéma  ->  cinéma\n",
            "France  ->  France\n",
            "monde  ->  monde\n",
            "métier  ->  métier\n",
            "critique  ->  critique\n",
            "cinéma  ->  cinéma\n",
            "monde  ->  monde\n",
            "rêves  ->  rêve\n",
            "Hollywood  ->  Hollywood\n",
            "crise  ->  crise\n",
            "économie  ->  économie\n",
            "France  ->  France\n",
            "menacée  ->  menacer\n",
            "mondialisation  ->  mondialisation\n",
            "temps  ->  temps\n",
            "crise  ->  crise\n",
            "reconstruire  ->  reconstruire\n",
            "industrie  ->  industrie\n",
            "art  ->  art\n",
            "usine  ->  usine\n",
            "ferme  ->  ferme\n",
            "économie  ->  économie\n"
          ]
        }
      ],
      "source": [
        "for token in filtered_sent:\n",
        "    print(token.text,' -> ',token.lemma_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e253391",
      "metadata": {
        "id": "0e253391"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}